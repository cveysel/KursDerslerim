{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix, classification_report\n",
    "\n",
    "# -----------------------------\n",
    "# METRIC CALCULATION FUNCTION\n",
    "# -----------------------------\n",
    "def calculate_classification_metrics(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true, predicted, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true, predicted, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL LIST\n",
    "# -----------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# RESULTS STORAGE LIST\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN AND EVALUATE ALL MODELS\n",
    "# -----------------------------\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc, train_prec, train_rec, train_f1 = calculate_classification_metrics(y_train, y_train_pred)\n",
    "    test_acc, test_prec, test_rec, test_f1 = calculate_classification_metrics(y_test, y_test_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Train Precision\": train_prec,\n",
    "        \"Train Recall\": train_rec,\n",
    "        \"Train F1\": train_f1,\n",
    "        \"Test Accuracy\": test_acc,\n",
    "        \"Test Precision\": test_prec,\n",
    "        \"Test Recall\": test_rec,\n",
    "        \"Test F1\": test_f1\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# DISPLAY RESULTS AS A TABLE\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"Test Accuracy\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Model Comparison Results:\")\n",
    "print(results_df.round(4))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#aÅŸaÄŸÄ±daki fonksiyon ile verilen korelasyon deÄŸerinden yÃ¼ksek korelasyon varsa o deÄŸerin adlarÄ±nÄ± liste olarak getirecek. iÅŸe yarar bir kod\n",
    "def corelation_for_dropping(df,threshold):\n",
    "    corr = df.corr()\n",
    "    columns_to_drop = set()\n",
    "    for x in range(len(corr.columns)):\n",
    "        for j in range(x):\n",
    "            if abs((corr.iloc[x,j])) > threshold:\n",
    "                columns_to_drop.add(corr.columns[x])\n",
    "    return columns_to_drop\n"
   ],
   "id": "f74ba4e4545eac63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_model_metrics(true,predicted):\n",
    "    mae = mean_absolute_error(true,predicted)\n",
    "    mse = mean_squared_error(true,predicted)\n",
    "    r2 = r2_score(true,predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true,predicted))\n",
    "    return mae,mse,r2,rmse"
   ],
   "id": "fdcc90bb1dd94b30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#outlier bulma fonksiyonu\n",
    "def find_outliers_iqr(df, threshold):\n",
    "    outlier_summary = {}\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    print(numeric_cols)\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        iqr = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - threshold * iqr\n",
    "        upper_bound = Q3 + threshold * iqr\n",
    "\n",
    "        outliers = df[ (df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "        outlier_summary[col] = {\n",
    "            \"outlier_count\": outliers.shape[0],\n",
    "            \"outlier_percentage\": outliers.shape[0] / df.shape[0],\n",
    "            \"lower_bound\": lower_bound,\n",
    "            \"upper_bound\": upper_bound,\n",
    "        }\n",
    "    return pd.DataFrame(outlier_summary)\n"
   ],
   "id": "5fb8dccacfcf8dd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# hedef kolondaki outlier datalarÄ± silme\n",
    "def remove_outliers_from_column(df, target_col, threshold=1.5):\n",
    "    Q1 = df[target_col].quantile(0.25)\n",
    "    Q3 = df[target_col].quantile(0.75)\n",
    "    iqr = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - threshold * iqr\n",
    "    upper_bound = Q3 + threshold * iqr\n",
    "\n",
    "    return df[(df[target_col] >= lower_bound) & (df[target_col] <= upper_bound)]"
   ],
   "id": "f476dbb63b47e02e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#tÃ¼m kolonlardaki outlier datalarÄ± silme\n",
    "def remove_outliers_from_all_column(df,threshold=1.5):\n",
    "    df_clean = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        iqr = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - threshold * iqr\n",
    "        upper_bound = Q3 + threshold * iqr\n",
    "\n",
    "        df_clean =  df_clean[ (df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean.copy()\n"
   ],
   "id": "17953c1afddc1d9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96f5254dd27e7a0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
